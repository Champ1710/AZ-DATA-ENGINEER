# Responsibilities of a Data Engineer:
The overarching responsibility of a data engineer is to provide `analytics-ready` data to `data consumers.` Data is analytics-ready when it is:
- Accurate
- Reliable
- Complies to regulations it is governed by, 
- Accessible to consumers when they need it.

 #### At a broad level, Data Engineers:
- Extract, organize, and integrate data from disparate sources, 
- Prepare data for analysis and reporting by transforming and cleansing it, 
- Design and manage data pipelines that encompass the journey of data from source to destination systems
- Setup and manage the infrastructure required for the ingestion, processing, and storage of data.

#### This can include:
- Data platforms,
 - Data stores for aggregating source data.
 - Distributed systems for large-scale processing of data.
- Data repositories for storage and dissemination of analysis-ready data.

## Technical, Functional, and Soft skills that you may need as a Data Engineer.
#### Let’s begin with the technical skills:
### Operating System:
- Knowledge of working with `operating system` including commonly used `administrative tools,` `system utilities` and `commands.`
### Infrastructure Components:
- Knowledge of `infrastructure components,` such as `virtual machines,` `networking,` and `application services,` such as `load balancing` and `application performance monitoring`. 
### Cloud:
- Cloud-based services such as those offered by `Amazon,` `Google,` `IBM,` and `Microsoft.`
### Databases:
- Experience of working with `databases` and `data warehouses,` which include: `RDBMSes` such as `IBM DB2,` `MySQL,` `Oracle Database,` and `PostgreSQL.`
- NoSQL databases such as `Redis,` `MongoDB,` `Cassandra,` and `Neo4J.`
### DataWarehouses:
- Data warehouses such as `Oracle Exadata,` `IBM Db2 Warehouse on Cloud,` `IBM Netezza Performance Server,` and `Amazon RedShift.`
### Data Pipelines:
- A high-level of proficiency working with `data pipelines.` Popular data pipeline solutions include `Apache Beam,` `AirFlow,` and `DataFLow.`
### ETL Tools:

- Experience of working with `ETL tools` such as `IBM Infosphere Information Server,` `AWS Glue,` and `Improvado.`
### Languages:
- Proficiency in languages for `querying,` `manipulating,` and `processing data.`  such as `SQL` for `relational databases` and `SQL-like` query languages for `NoSQL databases.`
- Programming languages such as `Python,` `R,` and `Java.`
### BigData Tools:
- Familiarity with `Big Data processing tools` such as `Hadoop,` `Hive,` and `Spark.`

## Functional skills that will serve you as a Data Engineer, include:
- The ability to convert `business requirements` into `technical specifications.`
- The ability to work with the complete `software development lifecycle` which includes: `Ideation, Architecture, Design, Prototyping, Testing, Deployment, and Monitoring.`
 - An understanding of `data’s potential` in business.
 - An understanding of the `risks` of `poor data management` which essentially covers `data quality, privacy, security, and compliance.`

## Data engineering is a team sport.
#### Interpersonal skills, teamwork, and collaboration, therefore, are essential for data engineers.
You could have multiple data engineers bringing in their specialization to `collaborate` on a project, closely interacting with the data consumers—which includes the `analysts,` `data scientists,` `business users,` and `other technical teams.` 

 As a data engineer, you need to be able to communicate effectively with both technical and non-technical stakeholders in a manner that a clear understanding can be established.

## Data engineering requires a broad set of skillsets.
No one data engineer can `possibly master` each one of `these skills,` which means you essentially need to select `one or more specialization areas,` but have a good understanding of all areas so that you can make more `informed decisions.` Your skills will grow over time with experience, the areas you choose to focus on, and the time you invest in upskilling yourself.
